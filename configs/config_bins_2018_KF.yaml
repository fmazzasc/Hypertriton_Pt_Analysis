ANALYSIS_RESULTS_PATH: "/data/fmazzasc/PbPb_2body/2018/AnalysisResults_18qr.root"
DATA_PATH: "/data/fmazzasc/PbPb_2body/KF/AnalysisResults.root"
MC_SIGNAL_PATH: "/data/fmazzasc/PbPb_2body/KF/AnalysisResults_MC.root"
LS_BACKGROUND_PATH: ""
RESULTS_SUBDIR: "/bins_offline_2018_KF"


PT_BINS_CENT: [[[3,3.5], [3.5,4], [4, 4.5],[4.5,5],[5,6], [6,9]], [[2, 3],[3,4],[4,5],[5,9]], [[2, 3],[3,4],[4,5],[5,9]], [[2,9]]]
CENTRALITY_LIST:  [[0, 10],  [10,30], [30, 50], [50,90]]

# PT_BINS_CENT: [[[2,9]], [[2,9]], [[2,9]], [[2,9]]]

PT_BINS: [[2, 3],[3,4],[4,5],[5,7], [7,9]]
CENTRALITY_LIST:  [[0, 10],  [10,30], [30, 50], [50,90]]

MERGE_SAMPLES: False
AOD: True
KINT7: False
USETOF: False
TRIGGERED: False

MAX_EFF: 0.99

RANDOM_STATE: 42

HYPERPARAMS:
  max_depth: 13
  learning_rate: 0.0982
  n_estimators: 181
  gamma: 0.4467
  min_child_weight: 5.75
  subsample: 0.74
  colsample_bytree: 0.57
  seed: 42

HYPERPARAMS_RANGES:
  # booster parameters
  max_depth: !!python/tuple [5, 20] # defines the maximum depth of a single tree (regularization)
  learning_rate: !!python/tuple [0.01, 0.3] # learning rate
  n_estimators: !!python/tuple [50, 500] # number of boosting trees
  gamma: !!python/tuple [0.3, 1.1] # specifies the minimum loss reduction required to make a split
  min_child_weight: !!python/tuple [1, 12]
  subsample: !!python/tuple [0.5, 0.9] # denotes the fraction of observations to be randomly samples for each tree
  colsample_bytree: !!python/tuple [0.5, 0.9] # denotes the fraction of columns to be randomly samples for each tree

TRAINING_COLUMNS:
  - V0CosPA
  - ct
  - ProngsDCA
  - PiProngPvDCAXY #pi da vertice primario
  - He3ProngPvDCAXY
  - He3ProngPvDCA # totale
  - PiProngPvDCA
  - NpidClustersHe3
  - TPCnSigmaHe3
  - TPCnSigmaPi
  # - NitsClustersHe3
